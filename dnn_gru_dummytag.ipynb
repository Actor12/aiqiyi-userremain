{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright IQIYI 2021\n",
    "http://challenge.ai.iqiyi.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/new_data_B/\"\n",
    "model_dir = \"./data/model/best_model.h5\"\n",
    "submit_dir = \"./data/submit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#制作一个迭代器，迭代器里面的每个元素是一个bt=n的step\n",
    "#https://blog.csdn.net/weixin_37737254/article/details/103884255\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size):\n",
    "        self.data = df\n",
    "        self.num = df.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.fea = ['father_id_score', 'cast_id_score', 'tag_score',\n",
    "       'device_type', 'device_ram', 'device_rom', 'sex', 'age', 'education',\n",
    "       'occupation_status', 'territory_score','launch_times', \n",
    "       'launch_times_31', 'launch_times_15', 'launch_times_7', 'playtime_31',\n",
    "       'playtime_15', 'playtime_7']#'launch_date_len_target_enc','start_end_launch',目前最佳只有钱18个,'launch_date_len','launch_type_0', 'launch_type_1'\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.num / self.batch_size)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        batch_data = self.data.iloc[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        input_1 = np.array([i for i in batch_data.launch_seq_31])\n",
    "        input_2 = np.array([i for i in batch_data.playtime_seq])\n",
    "        input_3 = np.array([i for i in batch_data.duration_prefer])\n",
    "        input_4 = np.array([i for i in batch_data.interact_prefer])\n",
    "        input_5 = np.array(batch_data[self.fea])\n",
    "        #以上特征要做成[[][][]]这样的形式读取\n",
    "        \n",
    "        output = np.array(batch_data.label)\n",
    "\n",
    "        return (input_1, input_2, input_3, input_4, input_5), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA = pd.read_csv(\"./data/new_data/test_data.txt\", sep=\"\\t\")\n",
    "testA[\"launch_seq_31\"] = testA.launch_seq_31.apply(lambda x: json.loads(x))\n",
    "testA[\"playtime_seq\"] = testA.playtime_seq.apply(lambda x: json.loads(x))\n",
    "testA[\"duration_prefer\"] = testA.duration_prefer.apply(lambda x: json.loads(x))\n",
    "testA[\"interact_prefer\"] = testA.interact_prefer.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB = pd.read_csv(\"./data/new_data_B/test_data.txt\", sep=\"\\t\")\n",
    "testB[\"launch_seq_31\"] = testB.launch_seq_31.apply(lambda x: json.loads(x))\n",
    "testB[\"playtime_seq\"] = testB.playtime_seq.apply(lambda x: json.loads(x))\n",
    "testB[\"duration_prefer\"] = testB.duration_prefer.apply(lambda x: json.loads(x))\n",
    "testB[\"interact_prefer\"] = testB.interact_prefer.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_A = DataGenerator(testA,100)\n",
    "new_test_B = DataGenerator(testB,100)\n",
    "#重新加载当前折最优的模型\n",
    "best_model = tf.keras.models.load_model(model_dir)\n",
    "#测试集推理\n",
    "test_predA =  best_model.predict(new_test_A, steps=len(new_test_A))[:,0]\n",
    "test_predB =  best_model.predict(new_test_B, steps=len(new_test_B))[:,0]\n",
    "\n",
    "testA['prediction'] = list(test_predA)\n",
    "testB['prediction'] = list(test_predB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(x):\n",
    "    if x<0.3:\n",
    "        return 0\n",
    "    elif x>0.7 and x<1.3:\n",
    "        return 1\n",
    "    elif x>1.7 and x<2.3:\n",
    "        return 2\n",
    "    elif x>2.7 and x<3.3:\n",
    "        return 3\n",
    "    elif x>3.7 and x<4.3:\n",
    "        return 4\n",
    "    elif x>4.7 and x<5.3:\n",
    "        return 5\n",
    "    elif x>5.7 and x<6.3:\n",
    "        return 6\n",
    "    elif x>6.7 and x<7.3:\n",
    "        return 7\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  end_date  label                                    launch_date  \\\n",
      "0  10007813       205      0                                     [118, 141]   \n",
      "1  10052988       210      0                                     [147, 149]   \n",
      "2  10279068       200      1       [134, 158, 178, 179, 180, 181, 196, 197]   \n",
      "3  10546696       216      1  [156, 178, 179, 184, 185, 187, 204, 207, 208]   \n",
      "4  10406659       183      0                                [104, 113, 141]   \n",
      "\n",
      "                   launch_type  launch_times  launch_type_0  launch_type_1  \\\n",
      "0                       [0, 1]     -0.498189      -0.558385       1.141663   \n",
      "1                       [0, 0]     -0.498189      -0.457282      -0.611804   \n",
      "2     [1, 1, 1, 0, 0, 0, 0, 0]      0.115362      -0.153974       4.648597   \n",
      "3  [0, 1, 0, 0, 0, 0, 0, 0, 0]      0.217620       0.149333       1.141663   \n",
      "4                    [0, 0, 0]     -0.395931      -0.356179      -0.611804   \n",
      "\n",
      "   launch_type_01rate  start_end_launch  ... device_ram device_rom       sex  \\\n",
      "0            1.146369          0.192987  ...   0.175924  -0.815578 -0.955892   \n",
      "1           -0.528554         -0.812643  ...   0.000000   0.000000  0.000000   \n",
      "2            0.727638          2.108472  ...   1.083590  -0.155943 -0.955892   \n",
      "3           -0.156349          1.581714  ...  -0.753798  -0.854838  1.046141   \n",
      "4           -0.528554          0.863407  ...  -1.531523  -1.069457  1.046141   \n",
      "\n",
      "        age  education  occupation_status  territory_score  \\\n",
      "0 -0.319111   0.755516           0.746096         0.000000   \n",
      "1  0.000000   0.000000           0.000000         0.000000   \n",
      "2 -0.319111  -0.544818           0.746096        -0.128893   \n",
      "3 -0.319111  -0.544818          -1.340308        -0.761475   \n",
      "4  0.828011  -0.544818          -1.340308        -0.871001   \n",
      "\n",
      "                     interact_prefer  prediction launch_date_len  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    0.054507             NaN  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    0.000000             NaN  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    0.770307             NaN  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    1.093312             NaN  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    0.000000             NaN  \n",
      "\n",
      "[5 rows x 35 columns] 28713\n"
     ]
    }
   ],
   "source": [
    "tmpA = testA['prediction'].apply(lambda x:select(x))\n",
    "tmpB = testB['prediction'].apply(lambda x:select(x))\n",
    "\n",
    "testA['label'] = list(tmpA)\n",
    "testB['label'] = list(tmpB)\n",
    "\n",
    "test = pd.concat([testA,testB],axis=0)\n",
    "test = test[test['label']!=-1]\n",
    "print(test.head(),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train = pd.read_csv(data_dir + \"train_data.txt\", sep=\"\\t\")\n",
    "train[\"launch_seq_31\"] = train.launch_seq_31.apply(lambda x: json.loads(x))\n",
    "train[\"playtime_seq\"] = train.playtime_seq.apply(lambda x: json.loads(x))\n",
    "train[\"duration_prefer\"] = train.duration_prefer.apply(lambda x: json.loads(x))\n",
    "train[\"interact_prefer\"] = train.interact_prefer.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aiyiqi_metric(y_true,y_pred):\n",
    "    y_true = list(y_true)\n",
    "    y_pred = list(y_pred)\n",
    "    score = 0\n",
    "    for i in range(len(y_true)):\n",
    "        score += abs(y_true[i]-y_pred[i])/7\n",
    "    return 100*(1-score/len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####第1折####\n",
      "train len: 502774\n",
      "val len: 125694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1964/1964 [==============================] - 24s 11ms/step - loss: 1.5163 - mse: 1.5163 - val_loss: 1.5251 - val_mse: 1.5251\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52512, saving model to ./data/model\\best_model.h5\n",
      "Epoch 2/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5155 - mse: 1.5155 - val_loss: 1.5249 - val_mse: 1.5249\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52512 to 1.52488, saving model to ./data/model\\best_model.h5\n",
      "Epoch 3/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5144 - mse: 1.5144 - val_loss: 1.5268 - val_mse: 1.5268\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.52488\n",
      "Epoch 4/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.5134 - mse: 1.5134 - val_loss: 1.5246 - val_mse: 1.5246\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.52488 to 1.52464, saving model to ./data/model\\best_model.h5\n",
      "Epoch 5/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.5121 - mse: 1.5121 - val_loss: 1.5254 - val_mse: 1.5254\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.52464\n",
      "Epoch 6/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5117 - mse: 1.5117 - val_loss: 1.5272 - val_mse: 1.5272\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.52464\n",
      "Epoch 7/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5016 - mse: 1.5016 - val_loss: 1.5221 - val_mse: 1.5221\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.52464 to 1.52209, saving model to ./data/model\\best_model.h5\n",
      "Epoch 8/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4996 - mse: 1.4996 - val_loss: 1.5214 - val_mse: 1.5214\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.52209 to 1.52142, saving model to ./data/model\\best_model.h5\n",
      "Epoch 9/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4990 - mse: 1.4990 - val_loss: 1.5217 - val_mse: 1.5217\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.52142\n",
      "Epoch 10/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4986 - mse: 1.4986 - val_loss: 1.5221 - val_mse: 1.5221\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.52142\n",
      "Epoch 11/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4970 - mse: 1.4970 - val_loss: 1.5217 - val_mse: 1.5217\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.52142\n",
      "#####第2折####\n",
      "train len: 502774\n",
      "val len: 125694\n",
      "Epoch 1/20\n",
      "1964/1964 [==============================] - 25s 11ms/step - loss: 1.5146 - mse: 1.5146 - val_loss: 1.5089 - val_mse: 1.5089\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50891, saving model to ./data/model\\best_model.h5\n",
      "Epoch 2/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5125 - mse: 1.5125 - val_loss: 1.5130 - val_mse: 1.5130\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.50891\n",
      "Epoch 3/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.5113 - mse: 1.5113 - val_loss: 1.5136 - val_mse: 1.5136\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.50891\n",
      "Epoch 4/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5010 - mse: 1.5010 - val_loss: 1.5081 - val_mse: 1.5081\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.50891 to 1.50810, saving model to ./data/model\\best_model.h5\n",
      "Epoch 5/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4990 - mse: 1.4990 - val_loss: 1.5077 - val_mse: 1.5077\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50810 to 1.50769, saving model to ./data/model\\best_model.h5\n",
      "Epoch 6/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4983 - mse: 1.4983 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.50769 to 1.50722, saving model to ./data/model\\best_model.h5\n",
      "Epoch 7/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4979 - mse: 1.4979 - val_loss: 1.5074 - val_mse: 1.5074\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.50722\n",
      "Epoch 8/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4974 - mse: 1.4974 - val_loss: 1.5074 - val_mse: 1.5074\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.50722\n",
      "Epoch 9/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4959 - mse: 1.4959 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.50722 to 1.50718, saving model to ./data/model\\best_model.h5\n",
      "Epoch 10/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4957 - mse: 1.4957 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.50718 to 1.50717, saving model to ./data/model\\best_model.h5\n",
      "Epoch 11/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4955 - mse: 1.4955 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50717\n",
      "Epoch 12/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4955 - mse: 1.4955 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.50717\n",
      "Epoch 13/20\n",
      "1964/1964 [==============================] - 23s 11ms/step - loss: 1.4955 - mse: 1.4955 - val_loss: 1.5072 - val_mse: 1.5072\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.50717\n",
      "#####第3折####\n",
      "train len: 502774\n",
      "val len: 125694\n",
      "Epoch 1/20\n",
      "1964/1964 [==============================] - 25s 11ms/step - loss: 1.5096 - mse: 1.5096 - val_loss: 1.5086 - val_mse: 1.5086\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50862, saving model to ./data/model\\best_model.h5\n",
      "Epoch 2/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5080 - mse: 1.5080 - val_loss: 1.5174 - val_mse: 1.5174\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.50862\n",
      "Epoch 3/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5067 - mse: 1.5067 - val_loss: 1.5157 - val_mse: 1.5157\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.50862\n",
      "Epoch 4/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4958 - mse: 1.4958 - val_loss: 1.5102 - val_mse: 1.5102\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.50862\n",
      "#####第4折####\n",
      "train len: 502775\n",
      "val len: 125693\n",
      "Epoch 1/20\n",
      "1964/1964 [==============================] - 25s 12ms/step - loss: 1.5124 - mse: 1.5124 - val_loss: 1.4992 - val_mse: 1.4992\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.49920, saving model to ./data/model\\best_model.h5\n",
      "Epoch 2/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5105 - mse: 1.5105 - val_loss: 1.5005 - val_mse: 1.5005\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.49920\n",
      "Epoch 3/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.5090 - mse: 1.5090 - val_loss: 1.5004 - val_mse: 1.5004\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49920\n",
      "Epoch 4/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4982 - mse: 1.4982 - val_loss: 1.4956 - val_mse: 1.4956\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.49920 to 1.49560, saving model to ./data/model\\best_model.h5\n",
      "Epoch 5/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4963 - mse: 1.4963 - val_loss: 1.4956 - val_mse: 1.4956\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.49560\n",
      "Epoch 6/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4955 - mse: 1.4955 - val_loss: 1.4957 - val_mse: 1.4957\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.49560\n",
      "Epoch 7/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4938 - mse: 1.4938 - val_loss: 1.4955 - val_mse: 1.4955\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.49560 to 1.49547, saving model to ./data/model\\best_model.h5\n",
      "Epoch 8/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4936 - mse: 1.4936 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.49547 to 1.49539, saving model to ./data/model\\best_model.h5\n",
      "Epoch 9/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4935 - mse: 1.4935 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.49539 to 1.49538, saving model to ./data/model\\best_model.h5\n",
      "Epoch 10/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.49538 to 1.49537, saving model to ./data/model\\best_model.h5\n",
      "Epoch 11/20\n",
      "1964/1964 [==============================] - 21s 11ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.49537 to 1.49536, saving model to ./data/model\\best_model.h5\n",
      "Epoch 12/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.49536 to 1.49536, saving model to ./data/model\\best_model.h5\n",
      "Epoch 13/20\n",
      "1964/1964 [==============================] - 19s 10ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.49536 to 1.49536, saving model to ./data/model\\best_model.h5\n",
      "Epoch 14/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4932 - mse: 1.4932 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.49536 to 1.49536, saving model to ./data/model\\best_model.h5\n",
      "Epoch 15/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4932 - mse: 1.4932 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.49536\n",
      "Epoch 16/20\n",
      "1964/1964 [==============================] - 21s 10ms/step - loss: 1.4932 - mse: 1.4932 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.49536\n",
      "Epoch 17/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.4932 - mse: 1.4932 - val_loss: 1.4954 - val_mse: 1.4954\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.49536\n",
      "#####第5折####\n",
      "train len: 502775\n",
      "val len: 125693\n",
      "Epoch 1/20\n",
      "1964/1964 [==============================] - 23s 10ms/step - loss: 1.5054 - mse: 1.5054 - val_loss: 1.5090 - val_mse: 1.5090\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50898, saving model to ./data/model\\best_model.h5\n",
      "Epoch 2/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.5037 - mse: 1.5037 - val_loss: 1.5136 - val_mse: 1.5136\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.50898\n",
      "Epoch 3/20\n",
      "1964/1964 [==============================] - 20s 10ms/step - loss: 1.5022 - mse: 1.5022 - val_loss: 1.5239 - val_mse: 1.5239\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.50898\n",
      "Epoch 4/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4909 - mse: 1.4909 - val_loss: 1.5080 - val_mse: 1.5080\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.50898 to 1.50800, saving model to ./data/model\\best_model.h5\n",
      "Epoch 5/20\n",
      "1964/1964 [==============================] - 23s 12ms/step - loss: 1.4890 - mse: 1.4890 - val_loss: 1.5078 - val_mse: 1.5078\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50800 to 1.50778, saving model to ./data/model\\best_model.h5\n",
      "Epoch 6/20\n",
      "1964/1964 [==============================] - 23s 11ms/step - loss: 1.4883 - mse: 1.4883 - val_loss: 1.5078 - val_mse: 1.5078\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.50778 to 1.50778, saving model to ./data/model\\best_model.h5\n",
      "Epoch 7/20\n",
      "1964/1964 [==============================] - 23s 12ms/step - loss: 1.4878 - mse: 1.4878 - val_loss: 1.5077 - val_mse: 1.5077\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.50778 to 1.50774, saving model to ./data/model\\best_model.h5\n",
      "Epoch 8/20\n",
      "1964/1964 [==============================] - 23s 12ms/step - loss: 1.4860 - mse: 1.4860 - val_loss: 1.5076 - val_mse: 1.5076\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.50774 to 1.50762, saving model to ./data/model\\best_model.h5\n",
      "Epoch 9/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4859 - mse: 1.4859 - val_loss: 1.5076 - val_mse: 1.5076\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.50762\n",
      "Epoch 10/20\n",
      "1964/1964 [==============================] - 23s 12ms/step - loss: 1.4858 - mse: 1.4858 - val_loss: 1.5077 - val_mse: 1.5077\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.50762\n",
      "Epoch 11/20\n",
      "1964/1964 [==============================] - 22s 11ms/step - loss: 1.4856 - mse: 1.4856 - val_loss: 1.5077 - val_mse: 1.5077\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50762\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aiyiqi_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-190b6208ef80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#计算整体验证集得分\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maiyiqi_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moof_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'多折验证集总体得分：{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aiyiqi_metric' is not defined"
     ]
    }
   ],
   "source": [
    "oof_pred = np.zeros(len(final_train))\n",
    "test_preds = np.zeros(len(testB))\n",
    "\n",
    "y = final_train['label']\n",
    "x = final_train.drop('label',axis=1)\n",
    "kfold = StratifiedKFold(random_state=2021,n_splits=5,shuffle=True)\n",
    "\n",
    "for kf,(train_idx,val_idx) in enumerate(kfold.split(x,y)):\n",
    "    print('#####第{}折####'.format(kf+1))\n",
    "    print('train len: {}'.format(len(train_idx)))\n",
    "    print('val len: {}'.format(len(val_idx)))\n",
    "    train_x = x.iloc[train_idx]\n",
    "    train_y = y.iloc[train_idx]\n",
    "    train_df = pd.concat([train_x,train_y],axis=1)\n",
    "    val_x = x.iloc[val_idx]\n",
    "    val_y = y.iloc[val_idx]\n",
    "    val_df = pd.concat([val_x,val_y],axis=1)\n",
    "\n",
    "    train_bt = DataGenerator(train_df,256)\n",
    "    val_bt = DataGenerator(val_df,256)\n",
    "    \n",
    "    model = tf.keras.models.load_model('./data/model/best_model.h5')\n",
    "    #model = build_model(seq_len=32,dur_seq_len=16,inter_seq_len=11,feature_num=18)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0008),loss=\"mse\",metrics=[\"mse\"])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_mse\", patience=3, restore_best_weights=True)\n",
    "    lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(patience=2,monitor='val_mse', factor=0.1)\n",
    "    best_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_dir.format(kf+1),save_best_only=True, save_weights_only=False,verbose=1)\n",
    "    #model.fit(iter(train_bt),steps_per_epoch=len(train_bt),validation_data=iter(val_bt),validation_steps=len(val_bt),epochs=20,callbacks=[best_checkpoint,early_stopping,lr_reduce])\n",
    "    #model.save('./data/model/model_fold{}.h5'.format(kf))\n",
    "    model.fit_generator(generator=train_bt,\n",
    "                    steps_per_epoch=len(train_bt),\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_bt,\n",
    "                    validation_steps=len(val_bt),\n",
    "#                     use_multiprocessing=False,\n",
    "#                     workers=1,\n",
    "                    callbacks=[best_checkpoint,early_stopping,lr_reduce])\n",
    " \n",
    "    #重新加载当前折最优的模型\n",
    "    best_model = tf.keras.models.load_model(model_dir.format(kf+1))\n",
    "    \n",
    "    #验证集推理\n",
    "    val_pred =  best_model.predict(val_bt, steps=len(val_bt))[:,0]\n",
    "    oof_pred[val_idx] = val_pred\n",
    "    \n",
    "    #测试集推理\n",
    "    test_pred =  best_model.predict(new_test_B, steps=len(new_test_B))[:,0]\n",
    "    test_preds += test_pred\n",
    "    \n",
    "    \n",
    "#计算整体验证集得分\n",
    "y_true = final_train.label\n",
    "score = aiyiqi_metric(y_true,oof_pred)\n",
    "print('多折验证集总体得分：{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6188/6188 [==============================] - 60s 9ms/step - loss: 1.5036 - mse: 1.5036 - val_loss: 1.6021 - val_mse: 1.6021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60212, saving model to ./data/model\\model.h5\n",
      "Epoch 2/20\n",
      "6188/6188 [==============================] - 56s 9ms/step - loss: 1.5032 - mse: 1.5032 - val_loss: 1.6113 - val_mse: 1.6113\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.60212\n",
      "Epoch 3/20\n",
      "6188/6188 [==============================] - 55s 9ms/step - loss: 1.5013 - mse: 1.5013 - val_loss: 1.6107 - val_mse: 1.6107\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60212\n",
      "Epoch 4/20\n",
      "6188/6188 [==============================] - 55s 9ms/step - loss: 1.4854 - mse: 1.4854 - val_loss: 1.5989 - val_mse: 1.5989\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60212 to 1.59892, saving model to ./data/model\\model.h5\n",
      "Epoch 5/20\n",
      "6188/6188 [==============================] - 56s 9ms/step - loss: 1.4818 - mse: 1.4818 - val_loss: 1.6000 - val_mse: 1.6000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.59892\n",
      "Epoch 6/20\n",
      "6188/6188 [==============================] - 56s 9ms/step - loss: 1.4805 - mse: 1.4805 - val_loss: 1.5993 - val_mse: 1.5993\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.59892\n",
      "Epoch 7/20\n",
      "6188/6188 [==============================] - 55s 9ms/step - loss: 1.4776 - mse: 1.4776 - val_loss: 1.5993 - val_mse: 1.5993\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.59892\n",
      "得分：87.1214099419968\n"
     ]
    }
   ],
   "source": [
    "new_train = DataGenerator(final_train[10000:],100)\n",
    "new_val = DataGenerator(final_train.iloc[:10000],100)\n",
    "        \n",
    "model = tf.keras.models.load_model('./data/model/best_model.h5')\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0008),loss=\"mse\",metrics=[\"mse\"])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_mse\", patience=3, restore_best_weights=True)\n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(patience=2,monitor='val_mse', factor=0.1)\n",
    "best_checkpoint = tf.keras.callbacks.ModelCheckpoint('./data/model/model.h5',save_best_only=True, save_weights_only=False,verbose=1)\n",
    "#model.fit(iter(train_bt),steps_per_epoch=len(train_bt),validation_data=iter(val_bt),validation_steps=len(val_bt),epochs=20,callbacks=[best_checkpoint,early_stopping,lr_reduce])\n",
    "#model.save('./data/model/model_fold{}.h5'.format(kf))\n",
    "model.fit_generator(generator=new_train,\n",
    "                    steps_per_epoch=len(new_train),\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=new_val,\n",
    "                    validation_steps=len(new_val),\n",
    "#                     use_multiprocessing=False,\n",
    "#                     workers=1,\n",
    "                    callbacks=[best_checkpoint,early_stopping,lr_reduce])\n",
    "    \n",
    "#重新加载当前折最优的模型\n",
    "best_model = tf.keras.models.load_model('./data/model/model.h5')\n",
    "#测试集推理\n",
    "test_pred =  best_model.predict(new_test_B, steps=len(new_test_B))[:,0]\n",
    " \n",
    "#验证集推理\n",
    "val_pred =  best_model.predict(new_val, steps=len(new_val))[:,0]\n",
    "\n",
    "#计算整体验证集得分\n",
    "y_true = final_train.iloc[:10000]['label']\n",
    "score = aiyiqi_metric(y_true,val_pred)\n",
    "print('得分：{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存测试集结果\n",
    "prediction = test_pred\n",
    "testB['prediction'] = list(prediction)\n",
    "res = testB[[\"user_id\", \"prediction\"]]\n",
    "res.to_csv(submit_dir + \"submit_B.csv\", index=False, header=False, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
